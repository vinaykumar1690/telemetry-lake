
=======================================================================
  Telemetry Lake has been deployed!
=======================================================================

Namespace: {{ .Values.namespace }}

Components:
{{- if .Values.ingester.enabled }}
  - Ingester (HTTP receiver for OTLP logs -> Kafka producer)
{{- end }}
{{- if .Values.appender.enabled }}
  - Appender (Kafka consumer -> Iceberg writer)
{{- end }}
{{- if .Values.kafka.enabled }}
  - Kafka (Event streaming for log buffering)
{{- end }}
  - MinIO (S3-compatible storage)
  - Nessie (Iceberg REST Catalog)
  - DuckDB (Query engine with Iceberg support)

-----------------------------------------------------------------------
WAIT FOR PODS TO BE READY
-----------------------------------------------------------------------

{{- if .Values.kafka.enabled }}
kubectl wait --for=condition=ready pod -l app=kafka -n {{ .Values.namespace }} --timeout=120s
{{- end }}
kubectl wait --for=condition=ready pod -l app=minio -n {{ .Values.namespace }} --timeout=120s
kubectl wait --for=condition=ready pod -l app=nessie -n {{ .Values.namespace }} --timeout=120s
kubectl wait --for=condition=ready pod -l app=duckdb -n {{ .Values.namespace }} --timeout=120s
{{- if .Values.ingester.enabled }}
kubectl wait --for=condition=ready pod -l app=ingester -n {{ .Values.namespace }} --timeout=120s
{{- end }}
{{- if .Values.appender.enabled }}
kubectl wait --for=condition=ready pod -l app=appender -n {{ .Values.namespace }} --timeout=120s
{{- end }}

-----------------------------------------------------------------------
ACCESS DUCKDB
-----------------------------------------------------------------------

Start an interactive DuckDB session:

  kubectl exec -it -n {{ .Values.namespace }} duckdb-0 -- duckdb

-----------------------------------------------------------------------
QUICK START: CREATE AN ICEBERG TABLE
-----------------------------------------------------------------------

Once inside DuckDB, run these commands:

  -- Load extensions
  LOAD iceberg;
  LOAD httpfs;

  -- Configure S3 for MinIO
  CREATE SECRET s3_secret (
      TYPE S3,
      KEY_ID '{{ .Values.minio.accessKey }}',
      SECRET '{{ .Values.minio.secretKey }}',
      ENDPOINT 'minio:9000',
      USE_SSL false,
      URL_STYLE 'path'
  );

  -- Attach to Nessie catalog
  ATTACH 'nessie' AS nessie (
      TYPE ICEBERG,
      ENDPOINT 'http://nessie:19120/iceberg',
      WAREHOUSE '{{ .Values.nessie.warehouse }}'
  );

  -- Create a table
  CREATE TABLE nessie.main.test_table (
      id INTEGER,
      name VARCHAR,
      created_at TIMESTAMP
  );

  -- Insert data
  INSERT INTO nessie.main.test_table VALUES
      (1, 'Alice', '2024-01-01 00:00:00'),
      (2, 'Bob', '2024-01-02 00:00:00');

  -- Query data
  SELECT * FROM nessie.main.test_table;

-----------------------------------------------------------------------
SERVICE ENDPOINTS (Internal)
-----------------------------------------------------------------------

{{- if .Values.ingester.enabled }}
Ingester OTLP:     http://ingester:{{ .Values.ingester.service.port }}/v1/logs
{{- end }}
{{- if .Values.kafka.enabled }}
Kafka Bootstrap:   kafka:9092
Kafka Topic:       {{ .Values.kafka.topics.logs }}
{{- end }}
MinIO S3 API:      http://minio:9000
MinIO Console:     http://minio-console:9001
Nessie Catalog:    http://nessie:19120/iceberg/

-----------------------------------------------------------------------
PORT FORWARDING (Optional)
-----------------------------------------------------------------------

Access MinIO Console from your browser:

  kubectl port-forward -n {{ .Values.namespace }} svc/minio-console 9001:9001

Then open: http://localhost:9001
Credentials: {{ .Values.minio.accessKey }} / {{ .Values.minio.secretKey }}

{{- if .Values.ingester.enabled }}
-----------------------------------------------------------------------
SEND TELEMETRY LOGS
-----------------------------------------------------------------------

Send OTLP logs to the ingester from within the cluster:

  curl -X POST http://ingester:{{ .Values.ingester.service.port }}/v1/logs \
    -H "Content-Type: application/json" \
    -d '{"resourceLogs":[{"resource":{"attributes":[{"key":"service.name","value":{"stringValue":"test"}}]},"scopeLogs":[{"scope":{},"logRecords":[{"timeUnixNano":"1672531200000000000","severityText":"INFO","body":{"stringValue":"Hello from K8s"}}]}]}]}'

Port forward to send logs from your local machine:

  kubectl port-forward -n {{ .Values.namespace }} svc/ingester {{ .Values.ingester.service.port }}:{{ .Values.ingester.service.port }}

{{- end }}
{{- if .Values.kafka.enabled }}
-----------------------------------------------------------------------
KAFKA USAGE
-----------------------------------------------------------------------

Test Kafka connectivity:
  kubectl exec -n {{ .Values.namespace }} kafka-0 -- /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

Create the telemetry logs topic:
  kubectl exec -n {{ .Values.namespace }} kafka-0 -- /opt/kafka/bin/kafka-topics.sh --create --topic {{ .Values.kafka.topics.logs }} --bootstrap-server localhost:9092 --partitions {{ .Values.kafka.config.numPartitions }} --replication-factor {{ .Values.kafka.config.defaultReplicationFactor }}

Produce test messages:
  kubectl exec -it -n {{ .Values.namespace }} kafka-0 -- /opt/kafka/bin/kafka-console-producer.sh --topic {{ .Values.kafka.topics.logs }} --bootstrap-server localhost:9092

Consume messages:
  kubectl exec -it -n {{ .Values.namespace }} kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh --topic {{ .Values.kafka.topics.logs }} --from-beginning --bootstrap-server localhost:9092

{{- end }}
-----------------------------------------------------------------------
TROUBLESHOOTING
-----------------------------------------------------------------------

Check pod status:
  kubectl get pods -n {{ .Values.namespace }}

View logs:
{{- if .Values.ingester.enabled }}
  kubectl logs -n {{ .Values.namespace }} -l app=ingester
{{- end }}
{{- if .Values.appender.enabled }}
  kubectl logs -n {{ .Values.namespace }} -l app=appender
{{- end }}
{{- if .Values.kafka.enabled }}
  kubectl logs -n {{ .Values.namespace }} kafka-0
{{- end }}
  kubectl logs -n {{ .Values.namespace }} minio-0
  kubectl logs -n {{ .Values.namespace }} -l app=nessie
  kubectl logs -n {{ .Values.namespace }} duckdb-0

Test connectivity from DuckDB pod:
  kubectl exec -n {{ .Values.namespace }} duckdb-0 -- curl -s http://minio:9000/minio/health/live
  kubectl exec -n {{ .Values.namespace }} duckdb-0 -- curl -s http://nessie:19120/api/v2/config

-----------------------------------------------------------------------
CLEANUP
-----------------------------------------------------------------------

  helm uninstall {{ .Release.Name }} -n {{ .Values.namespace }}
  kubectl delete namespace {{ .Values.namespace }}

=======================================================================
